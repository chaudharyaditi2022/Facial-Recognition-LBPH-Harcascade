{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import getpass as gp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a7ec4",
   "metadata": {},
   "source": [
    "##  Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568af741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading harcascade model for face recognition\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Function to Crop face using haarcascade\n",
    "def  face_crop(image):\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_img, 1.3, 2)\n",
    "    \n",
    "    if faces == ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,width,hieght) in faces:\n",
    "        cropped_face = image[y:y+hieght, x:x+width]\n",
    "        \n",
    "    return cropped_face\n",
    "\n",
    " \n",
    "\n",
    "def CollectSampleImages(object_name):\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"faces/{}\".format(object_name))   \n",
    "    except FileExistsError:\n",
    "        print(\"Object with name {} already exists!! Try different name!!\".format(object_name))\n",
    "        return\n",
    "    \n",
    "    #Initialising\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    count = 0\n",
    "       \n",
    "    while True:\n",
    "        ret, img = cam.read()\n",
    "        if face_crop(img) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_crop(img),(250,250))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #Save file in in ./faces/ directory with unique name\n",
    "            file_path = \"./faces/{}/\".format(object_name) + str(count)+ \".jpg\"\n",
    "            cv2.imwrite(file_path, face)\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Cropped face' , face)\n",
    "\n",
    "        else:\n",
    "            print(\"Face not found !!\")\n",
    "\n",
    "        if cv2.waitKey(1) == 32 or count == 100: #Space bar is pressed\n",
    "            break;\n",
    "\n",
    "    #Release Camera and close window \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if count == 100:\n",
    "        print(\"Samples Collected Successfully in ./faces/{}/ directory\".format(object_name))\n",
    "    return\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectSampleImages(\"aditi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa953580",
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectSampleImages(\"adarsh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a51124",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5976adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainmodel(object_name):\n",
    "\n",
    "    data_path = \"./faces/{}/\".format(object_name)\n",
    "\n",
    "    #Including only those files which are in ./faces/user/ path\n",
    "    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "    # Create arrays for training data and labels\n",
    "    Training_Data, Labels = [], []\n",
    "    # Open training images in our datapath\n",
    "    # Create a numpy array for training data\n",
    "    for i, files in enumerate(onlyfiles):\n",
    "        image_path = data_path + files\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "\n",
    "    # Create a numpy array for both training data and labels\n",
    "    Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "    # Initialize facial recognizer\n",
    "    # model = cv2.face.createLBPHFaceRecognizer()\n",
    "    # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "    # pip install opencv-contrib-python\n",
    "    # model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "    model = cv2.face_LBPHFaceRecognizer.create()\n",
    "    # Let's train our model \n",
    "    model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "    print(\"Model trained sucessefully\")\n",
    "    return model\n",
    "\n",
    "#List storing models of all objects to be trained\n",
    "object_models, object_list = [], [\"Aditi\", \"Adarsh\"]\n",
    "object_models.append(trainmodel(\"aditi\"))\n",
    "object_models.append(trainmodel(\"adarsh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fcf7e",
   "metadata": {},
   "source": [
    "## Creating function to Send Whatsapp Message, Email and apply terraform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23455afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import pywhatkit as pwk\n",
    "from python_terraform import *\n",
    "from pprint import pprint \n",
    "\n",
    "def sendmail(sender_mail, reciever_mail,message, sender_password):\n",
    "    print(\"Sending mail...\")\n",
    "    try:\n",
    "        s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        s.starttls()\n",
    "        print(s.login(sender_mail, sender_password))\n",
    "        s.sendmail(sender_mail, reciever_mail, message)\n",
    "        s.quit()\n",
    "        print(\"Successfully sent email\")    \n",
    "    except Exception as e:\n",
    "        print(\"Error: unable to send email : {}\".format(e)) \n",
    "        \n",
    "def whatsapp(phone_num, message):\n",
    "    pwk.sendwhatmsg_instantly(phone_num,message)\n",
    "    \n",
    "def terraform_apply(workingDir):\n",
    "    try:\n",
    "        #Creating instance and volume using terraform\n",
    "        tf = Terraform(working_dir=workingDir)\n",
    "        tf.plan(no_color=IsFlagged, refresh=False, capture_output=True)\n",
    "        #approve = {\"auto-approve\": True}\n",
    "        tf.init()\n",
    "        pprint(tf.plan())\n",
    "        pprint(tf.apply(skip_plan=True))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Some Error occured!! {}\".format(e))\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19aed0",
   "metadata": {},
   "source": [
    "## Function to Recognize faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(object_models, object_list, face, image):\n",
    "    identity = \"\"\n",
    "    for i,model in enumerate(object_models):\n",
    "        result = model.predict(face)\n",
    "        max_confidence = 0\n",
    "        if result[1] < 500:\n",
    "            confidence = int( 100 * (1 - (result[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is {}'.format(object_list[i])\n",
    "            cv2.putText(image, display_string, (150, 120+(i*30)), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "        if confidence > 85:\n",
    "            if confidence > max_confidence:\n",
    "                max_confidence = confidence\n",
    "                identity = object_list[i]\n",
    "            cv2.putText(image, \"Hey {}\".format(identity), (250, 440), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "        else:\n",
    "            cv2.putText(image, \"Trying to Recognize..\", (200, 440), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,255), 2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "       \n",
    "    return identity    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7933f8",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_detector(image,size=0.5):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces == ():\n",
    "            return image,[]\n",
    "        \n",
    "    faces_detected = []   \n",
    "    for (x,y,width,hieght) in faces:\n",
    "        cv2.rectangle(image,(x,y),(x+width,y+hieght),(0,255,255),2)\n",
    "        cropped_face = img[y:y+hieght, x:x+width]\n",
    "        cropped_face = cv2.resize(cropped_face, (250, 250))\n",
    "        faces_detected.append(cropped_face)    \n",
    "    return image, faces_detected\n",
    "\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "task_status_a = False\n",
    "task_status_b = False\n",
    "exitKeyPressed = False\n",
    "password = gp.getpass(\"Enter Sender's mail Password: \")\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    image, faces_detected = face_detector(img)\n",
    "    try:\n",
    "        for i,face in enumerate(faces_detected): \n",
    "            face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Pass face to prediction models\n",
    "            object_name = recognize_face(object_models, object_list,face_gray, image)\n",
    "            #print(object_name)\n",
    "            \n",
    "            if not task_status_a and object_name == \"Aditi\":\n",
    "                sendmail(\"sender@gmail.com\", \"reciever@gmail.com\", \"This is face of Aditi\",password)\n",
    "                whatsapp(\"+91998*******\", \"Hi... Model recognized me!!\") \n",
    "                task_status_a = True\n",
    "            \n",
    "            elif not task_status_b and object_name == \"Adarsh\":\n",
    "                #Applying terraform code\n",
    "                terraform_apply('./terraform-ws/aws_ec2_ebs/')\n",
    "                task_status_b =True        \n",
    "            else:\n",
    "                cv2.putText(image, \"I dont know, who r u\", (230, 470), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image)\n",
    "                \n",
    "            if cv2.waitKey(1) == 32: #32 is the Space bar\n",
    "                exitKeyPressed = True\n",
    "                break  \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    finally:\n",
    "        if task_status_a and task_status_b:\n",
    "            print(\"ALL task Completed Successfully... You can exit now by pressing space key!\")\n",
    "        if exitKeyPressed or cv2.waitKey(1) == 32:\n",
    "            break \n",
    "\n",
    "    \n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()     \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
